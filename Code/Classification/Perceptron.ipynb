{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.neighbors._base\n",
    "from sklearn.utils import _safe_indexing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the modified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/data_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>valence_yr</th>\n",
       "      <th>popularity_yr</th>\n",
       "      <th>mode</th>\n",
       "      <th>key_0_yr</th>\n",
       "      <th>key_1_yr</th>\n",
       "      <th>key_2_yr</th>\n",
       "      <th>key_3_yr</th>\n",
       "      <th>key_4_yr</th>\n",
       "      <th>key_5_yr</th>\n",
       "      <th>key_6_yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>182347</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-4.860</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583424</td>\n",
       "      <td>35.272231</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>206972</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-19.898</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432251</td>\n",
       "      <td>3.672500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7950</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>314667</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>-10.202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447291</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>179747</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>-6.590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447291</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3020</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>498560</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>-16.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443625</td>\n",
       "      <td>3.419500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0        0.0131        0.2560       182347   0.895         0   \n",
       "1        0.9800        0.2770       206972   0.145         0   \n",
       "2        0.7950        0.6850       314667   0.483         0   \n",
       "3        0.6560        0.7880       179747   0.808         0   \n",
       "4        0.3020        0.0753       498560   0.150         0   \n",
       "\n",
       "   instrumentalness  liveness  loudness  popularity  speechiness  ...  \\\n",
       "0          0.000106    0.0821    -4.860          29       0.0707  ...   \n",
       "1          0.879000    0.1110   -19.898           0       0.0845  ...   \n",
       "2          0.878000    0.1130   -10.202           1       0.0337  ...   \n",
       "3          0.000000    0.1540    -6.590           0       0.0395  ...   \n",
       "4          0.884000    0.1210   -16.705           0       0.0371  ...   \n",
       "\n",
       "   valence_yr  popularity_yr  mode  key_0_yr  key_1_yr  key_2_yr  key_3_yr  \\\n",
       "0    0.583424      35.272231     1         0         0         1         0   \n",
       "1    0.432251       3.672500     1         1         0         0         0   \n",
       "2    0.447291       7.707000     1         0         0         0         1   \n",
       "3    0.447291       7.707000     1         0         0         0         1   \n",
       "4    0.443625       3.419500     1         1         0         0         0   \n",
       "\n",
       "   key_4_yr  key_5_yr  key_6_yr  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the data and its basic statistical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>valence_yr</th>\n",
       "      <th>popularity_yr</th>\n",
       "      <th>mode</th>\n",
       "      <th>key_0_yr</th>\n",
       "      <th>key_1_yr</th>\n",
       "      <th>key_2_yr</th>\n",
       "      <th>key_3_yr</th>\n",
       "      <th>key_4_yr</th>\n",
       "      <th>key_5_yr</th>\n",
       "      <th>key_6_yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>1.722300e+05</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.0</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "      <td>172230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.501914</td>\n",
       "      <td>0.536246</td>\n",
       "      <td>2.326718e+05</td>\n",
       "      <td>0.480989</td>\n",
       "      <td>0.067956</td>\n",
       "      <td>0.194968</td>\n",
       "      <td>0.211396</td>\n",
       "      <td>-11.777780</td>\n",
       "      <td>25.925913</td>\n",
       "      <td>0.105896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525269</td>\n",
       "      <td>25.711704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365111</td>\n",
       "      <td>0.058857</td>\n",
       "      <td>0.096325</td>\n",
       "      <td>0.052262</td>\n",
       "      <td>0.329356</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.005847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.379394</td>\n",
       "      <td>0.175858</td>\n",
       "      <td>1.471768e+05</td>\n",
       "      <td>0.272032</td>\n",
       "      <td>0.251670</td>\n",
       "      <td>0.332974</td>\n",
       "      <td>0.180661</td>\n",
       "      <td>5.690105</td>\n",
       "      <td>21.866745</td>\n",
       "      <td>0.183053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055638</td>\n",
       "      <td>15.219180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481463</td>\n",
       "      <td>0.235358</td>\n",
       "      <td>0.295037</td>\n",
       "      <td>0.222555</td>\n",
       "      <td>0.469981</td>\n",
       "      <td>0.289369</td>\n",
       "      <td>0.076241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.937000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378276</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>1.662000e+05</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>-14.935750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478115</td>\n",
       "      <td>7.750543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.523000</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>2.057175e+05</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>-10.867000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538017</td>\n",
       "      <td>31.149276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>2.656000e+05</td>\n",
       "      <td>0.708000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>-7.532000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563010</td>\n",
       "      <td>36.556552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>5.338302e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.855000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669676</td>\n",
       "      <td>50.873598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acousticness   danceability   duration_ms         energy  \\\n",
       "count  172230.000000  172230.000000  1.722300e+05  172230.000000   \n",
       "mean        0.501914       0.536246  2.326718e+05       0.480989   \n",
       "std         0.379394       0.175858  1.471768e+05       0.272032   \n",
       "min         0.000000       0.000000  4.937000e+03       0.000000   \n",
       "25%         0.091300       0.414000  1.662000e+05       0.248000   \n",
       "50%         0.523000       0.547000  2.057175e+05       0.463000   \n",
       "75%         0.896000       0.668000  2.656000e+05       0.708000   \n",
       "max         0.996000       0.988000  5.338302e+06       1.000000   \n",
       "\n",
       "            explicit  instrumentalness       liveness       loudness  \\\n",
       "count  172230.000000     172230.000000  172230.000000  172230.000000   \n",
       "mean        0.067956          0.194968       0.211396     -11.777780   \n",
       "std         0.251670          0.332974       0.180661       5.690105   \n",
       "min         0.000000          0.000000       0.000000     -60.000000   \n",
       "25%         0.000000          0.000000       0.099300     -14.935750   \n",
       "50%         0.000000          0.000498       0.138000     -10.867000   \n",
       "75%         0.000000          0.238000       0.270000      -7.532000   \n",
       "max         1.000000          1.000000       1.000000       3.855000   \n",
       "\n",
       "          popularity    speechiness  ...     valence_yr  popularity_yr  \\\n",
       "count  172230.000000  172230.000000  ...  172230.000000  172230.000000   \n",
       "mean       25.925913       0.105896  ...       0.525269      25.711704   \n",
       "std        21.866745       0.183053  ...       0.055638      15.219180   \n",
       "min         0.000000       0.000000  ...       0.378276       0.090909   \n",
       "25%         1.000000       0.035200  ...       0.478115       7.750543   \n",
       "50%        26.000000       0.045400  ...       0.538017      31.149276   \n",
       "75%        42.000000       0.076000  ...       0.563010      36.556552   \n",
       "max       100.000000       0.971000  ...       0.669676      50.873598   \n",
       "\n",
       "           mode       key_0_yr       key_1_yr       key_2_yr       key_3_yr  \\\n",
       "count  172230.0  172230.000000  172230.000000  172230.000000  172230.000000   \n",
       "mean        1.0       0.365111       0.058857       0.096325       0.052262   \n",
       "std         0.0       0.481463       0.235358       0.295037       0.222555   \n",
       "min         1.0       0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.0       0.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.0       0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.0       1.000000       0.000000       0.000000       0.000000   \n",
       "max         1.0       1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "            key_4_yr       key_5_yr       key_6_yr  \n",
       "count  172230.000000  172230.000000  172230.000000  \n",
       "mean        0.329356       0.092243       0.005847  \n",
       "std         0.469981       0.289369       0.076241  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000  \n",
       "75%         1.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 72 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the histogram of the data according to their popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(df[\"popularity\"])\n",
    "ax.set_xlabel(\"Popularity\")\n",
    "ax.set_ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have arrived at the threshold from the billboard charts and hence can split the data to two labels. These two labels are popular and non-popular songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretizing the songs into two labels of popular and non-popular.\n",
    "The songs with \"probability\" attribute less than 42 are non-popular.\n",
    "The other ones are popular\n",
    "The 0th label is the non-popular songs\n",
    "The 1th label is the popular songs \n",
    "So, the dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    127131\n",
       "1     45099\n",
       "Name: popularity, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_popularity = 42\n",
    "df[\"popularity\"] = [ 1 if i >= mean_popularity else 0 for i in df.popularity ]\n",
    "df.popularity.value_counts()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the \"popularity\" attribute from the data frame and declairing it as the dependant variable or the  output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"popularity\"].values\n",
    "X = df.drop([\"popularity\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into trainig data and testing data. The test size is 0.2 of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the dimensions of the arrays produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((172230, 71), (172230,))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model with its default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "model = Perceptron()\n",
    "clf = Perceptron(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running randomized gridsearch to reach the best set of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing gridsearch to find the best hyperparameters for this specific dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runeelwazlib/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.16420233, 0.19187629, 0.19626534, 0.19239914, 0.19167411,\n",
       "        0.19188261, 0.19243288, 0.19306827, 0.19492841, 0.19121671,\n",
       "        0.19386804, 0.20033109, 0.22155106, 0.21996677, 0.21847248,\n",
       "        0.22432661, 0.21803439, 0.24239576, 0.23211825, 0.2221868 ]),\n",
       " 'std_fit_time': array([0.02825534, 0.00069487, 0.00184524, 0.00147712, 0.00048411,\n",
       "        0.00033236, 0.000139  , 0.00130701, 0.00055528, 0.00101256,\n",
       "        0.00232351, 0.00841773, 0.01516831, 0.01318514, 0.0142231 ,\n",
       "        0.02046227, 0.01752675, 0.00436914, 0.00742424, 0.01401901]),\n",
       " 'mean_score_time': array([0.02256966, 0.02855921, 0.02350259, 0.02219713, 0.0219053 ,\n",
       "        0.02210879, 0.02195859, 0.02197325, 0.02179813, 0.02203023,\n",
       "        0.02198386, 0.02161109, 0.02175951, 0.02282059, 0.02292705,\n",
       "        0.02235281, 0.02310395, 0.02230012, 0.02443314, 0.02264738]),\n",
       " 'std_score_time': array([9.67979431e-05, 5.98216057e-03, 3.59535217e-04, 8.97645950e-05,\n",
       "        2.88605690e-04, 7.41481781e-05, 9.22679901e-05, 3.06367874e-05,\n",
       "        1.90973282e-04, 2.02775002e-04, 2.18629837e-04, 5.13792038e-05,\n",
       "        8.32080841e-05, 1.08945370e-03, 1.25384331e-03, 6.31451607e-04,\n",
       "        8.75234604e-04, 3.60906124e-03, 1.64914131e-03, 4.14609909e-04]),\n",
       " 'param_eta0': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 1,\n",
       "                    1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[10, 100, 1000, 10000, 10, 100, 1000, 10000, 10, 100,\n",
       "                    1000, 10000, 10, 100, 1000, 10000, 10, 100, 1000,\n",
       "                    10000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'eta0': 0.0001, 'max_iter': 10},\n",
       "  {'eta0': 0.0001, 'max_iter': 100},\n",
       "  {'eta0': 0.0001, 'max_iter': 1000},\n",
       "  {'eta0': 0.0001, 'max_iter': 10000},\n",
       "  {'eta0': 0.001, 'max_iter': 10},\n",
       "  {'eta0': 0.001, 'max_iter': 100},\n",
       "  {'eta0': 0.001, 'max_iter': 1000},\n",
       "  {'eta0': 0.001, 'max_iter': 10000},\n",
       "  {'eta0': 0.01, 'max_iter': 10},\n",
       "  {'eta0': 0.01, 'max_iter': 100},\n",
       "  {'eta0': 0.01, 'max_iter': 1000},\n",
       "  {'eta0': 0.01, 'max_iter': 10000},\n",
       "  {'eta0': 0.1, 'max_iter': 10},\n",
       "  {'eta0': 0.1, 'max_iter': 100},\n",
       "  {'eta0': 0.1, 'max_iter': 1000},\n",
       "  {'eta0': 0.1, 'max_iter': 10000},\n",
       "  {'eta0': 1, 'max_iter': 10},\n",
       "  {'eta0': 1, 'max_iter': 100},\n",
       "  {'eta0': 1, 'max_iter': 1000},\n",
       "  {'eta0': 1, 'max_iter': 10000}],\n",
       " 'split0_test_score': array([0.84899553, 0.84899553, 0.84899553, 0.84899553, 0.84899553,\n",
       "        0.84899553, 0.84899553, 0.84899553, 0.84899553, 0.84899553,\n",
       "        0.84899553, 0.84899553, 0.84272484, 0.84272484, 0.84272484,\n",
       "        0.84272484, 0.84272484, 0.84272484, 0.84272484, 0.84272484]),\n",
       " 'split1_test_score': array([0.80813447, 0.80813447, 0.80813447, 0.80813447, 0.80813447,\n",
       "        0.80813447, 0.80813447, 0.80813447, 0.80813447, 0.80813447,\n",
       "        0.80813447, 0.80813447, 0.83710736, 0.83710736, 0.83710736,\n",
       "        0.83710736, 0.83710736, 0.83710736, 0.83710736, 0.83710736]),\n",
       " 'mean_test_score': array([0.828565 , 0.828565 , 0.828565 , 0.828565 , 0.828565 , 0.828565 ,\n",
       "        0.828565 , 0.828565 , 0.828565 , 0.828565 , 0.828565 , 0.828565 ,\n",
       "        0.8399161, 0.8399161, 0.8399161, 0.8399161, 0.8399161, 0.8399161,\n",
       "        0.8399161, 0.8399161]),\n",
       " 'std_test_score': array([0.02043053, 0.02043053, 0.02043053, 0.02043053, 0.02043053,\n",
       "        0.02043053, 0.02043053, 0.02043053, 0.02043053, 0.02043053,\n",
       "        0.02043053, 0.02043053, 0.00280874, 0.00280874, 0.00280874,\n",
       "        0.00280874, 0.00280874, 0.00280874, 0.00280874, 0.00280874]),\n",
       " 'rank_test_score': array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = GridSearchCV(model, {\n",
    "    'eta0' : [ 0.0001, 0.001, 0.01, 0.1, 1], 'max_iter' : [10, 100, 1000, 10000]}, cv = 2, return_train_score = False)\n",
    "\n",
    "clf1.fit(X_train , y_train)\n",
    "clf1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.164202</td>\n",
       "      <td>0.028255</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'eta0': 0.0001, 'max_iter': 10}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.191876</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.028559</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'eta0': 0.0001, 'max_iter': 100}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196265</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.023503</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta0': 0.0001, 'max_iter': 1000}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.192399</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.022197</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'eta0': 0.0001, 'max_iter': 10000}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.191674</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'eta0': 0.001, 'max_iter': 10}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.191883</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'eta0': 0.001, 'max_iter': 100}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.192433</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.021959</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta0': 0.001, 'max_iter': 1000}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.193068</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'eta0': 0.001, 'max_iter': 10000}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.194928</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.021798</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{'eta0': 0.01, 'max_iter': 10}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.191217</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.022030</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>{'eta0': 0.01, 'max_iter': 100}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.193868</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta0': 0.01, 'max_iter': 1000}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.200331</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.021611</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'eta0': 0.01, 'max_iter': 10000}</td>\n",
       "      <td>0.848996</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>0.828565</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.221551</td>\n",
       "      <td>0.015168</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'eta0': 0.1, 'max_iter': 10}</td>\n",
       "      <td>0.842725</td>\n",
       "      <td>0.837107</td>\n",
       "      <td>0.839916</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.219967</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'eta0': 0.1, 'max_iter': 100}</td>\n",
       "      <td>0.842725</td>\n",
       "      <td>0.837107</td>\n",
       "      <td>0.839916</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.218472</td>\n",
       "      <td>0.014223</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta0': 0.1, 'max_iter': 1000}</td>\n",
       "      <td>0.842725</td>\n",
       "      <td>0.837107</td>\n",
       "      <td>0.839916</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.224327</td>\n",
       "      <td>0.020462</td>\n",
       "      <td>0.022353</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'eta0': 0.1, 'max_iter': 10000}</td>\n",
       "      <td>0.842725</td>\n",
       "      <td>0.837107</td>\n",
       "      <td>0.839916</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.218034</td>\n",
       "      <td>0.017527</td>\n",
       "      <td>0.023104</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'eta0': 1, 'max_iter': 10}</td>\n",
       "      <td>0.842725</td>\n",
       "      <td>0.837107</td>\n",
       "      <td>0.839916</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.242396</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'eta0': 1, 'max_iter': 100}</td>\n",
       "      <td>0.842725</td>\n",
       "      <td>0.837107</td>\n",
       "      <td>0.839916</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.232118</td>\n",
       "      <td>0.007424</td>\n",
       "      <td>0.024433</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta0': 1, 'max_iter': 1000}</td>\n",
       "      <td>0.842725</td>\n",
       "      <td>0.837107</td>\n",
       "      <td>0.839916</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.222187</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.022647</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'eta0': 1, 'max_iter': 10000}</td>\n",
       "      <td>0.842725</td>\n",
       "      <td>0.837107</td>\n",
       "      <td>0.839916</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_eta0  \\\n",
       "0        0.164202      0.028255         0.022570        0.000097     0.0001   \n",
       "1        0.191876      0.000695         0.028559        0.005982     0.0001   \n",
       "2        0.196265      0.001845         0.023503        0.000360     0.0001   \n",
       "3        0.192399      0.001477         0.022197        0.000090     0.0001   \n",
       "4        0.191674      0.000484         0.021905        0.000289      0.001   \n",
       "5        0.191883      0.000332         0.022109        0.000074      0.001   \n",
       "6        0.192433      0.000139         0.021959        0.000092      0.001   \n",
       "7        0.193068      0.001307         0.021973        0.000031      0.001   \n",
       "8        0.194928      0.000555         0.021798        0.000191       0.01   \n",
       "9        0.191217      0.001013         0.022030        0.000203       0.01   \n",
       "10       0.193868      0.002324         0.021984        0.000219       0.01   \n",
       "11       0.200331      0.008418         0.021611        0.000051       0.01   \n",
       "12       0.221551      0.015168         0.021760        0.000083        0.1   \n",
       "13       0.219967      0.013185         0.022821        0.001089        0.1   \n",
       "14       0.218472      0.014223         0.022927        0.001254        0.1   \n",
       "15       0.224327      0.020462         0.022353        0.000631        0.1   \n",
       "16       0.218034      0.017527         0.023104        0.000875          1   \n",
       "17       0.242396      0.004369         0.022300        0.003609          1   \n",
       "18       0.232118      0.007424         0.024433        0.001649          1   \n",
       "19       0.222187      0.014019         0.022647        0.000415          1   \n",
       "\n",
       "   param_max_iter                               params  split0_test_score  \\\n",
       "0              10     {'eta0': 0.0001, 'max_iter': 10}           0.848996   \n",
       "1             100    {'eta0': 0.0001, 'max_iter': 100}           0.848996   \n",
       "2            1000   {'eta0': 0.0001, 'max_iter': 1000}           0.848996   \n",
       "3           10000  {'eta0': 0.0001, 'max_iter': 10000}           0.848996   \n",
       "4              10      {'eta0': 0.001, 'max_iter': 10}           0.848996   \n",
       "5             100     {'eta0': 0.001, 'max_iter': 100}           0.848996   \n",
       "6            1000    {'eta0': 0.001, 'max_iter': 1000}           0.848996   \n",
       "7           10000   {'eta0': 0.001, 'max_iter': 10000}           0.848996   \n",
       "8              10       {'eta0': 0.01, 'max_iter': 10}           0.848996   \n",
       "9             100      {'eta0': 0.01, 'max_iter': 100}           0.848996   \n",
       "10           1000     {'eta0': 0.01, 'max_iter': 1000}           0.848996   \n",
       "11          10000    {'eta0': 0.01, 'max_iter': 10000}           0.848996   \n",
       "12             10        {'eta0': 0.1, 'max_iter': 10}           0.842725   \n",
       "13            100       {'eta0': 0.1, 'max_iter': 100}           0.842725   \n",
       "14           1000      {'eta0': 0.1, 'max_iter': 1000}           0.842725   \n",
       "15          10000     {'eta0': 0.1, 'max_iter': 10000}           0.842725   \n",
       "16             10          {'eta0': 1, 'max_iter': 10}           0.842725   \n",
       "17            100         {'eta0': 1, 'max_iter': 100}           0.842725   \n",
       "18           1000        {'eta0': 1, 'max_iter': 1000}           0.842725   \n",
       "19          10000       {'eta0': 1, 'max_iter': 10000}           0.842725   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.808134         0.828565        0.020431                9  \n",
       "1            0.808134         0.828565        0.020431                9  \n",
       "2            0.808134         0.828565        0.020431                9  \n",
       "3            0.808134         0.828565        0.020431                9  \n",
       "4            0.808134         0.828565        0.020431                9  \n",
       "5            0.808134         0.828565        0.020431                9  \n",
       "6            0.808134         0.828565        0.020431                9  \n",
       "7            0.808134         0.828565        0.020431                9  \n",
       "8            0.808134         0.828565        0.020431                9  \n",
       "9            0.808134         0.828565        0.020431                9  \n",
       "10           0.808134         0.828565        0.020431                9  \n",
       "11           0.808134         0.828565        0.020431                9  \n",
       "12           0.837107         0.839916        0.002809                1  \n",
       "13           0.837107         0.839916        0.002809                1  \n",
       "14           0.837107         0.839916        0.002809                1  \n",
       "15           0.837107         0.839916        0.002809                1  \n",
       "16           0.837107         0.839916        0.002809                1  \n",
       "17           0.837107         0.839916        0.002809                1  \n",
       "18           0.837107         0.839916        0.002809                1  \n",
       "19           0.837107         0.839916        0.002809                1  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Printing the accuracy scores for different permutations of the parameters eta0 and maximum iterations\n",
    "\n",
    "df = pd.DataFrame(clf1.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the classifier with the best set of hyperparameter (eta0 = 1 and maximum iterations = 10000)\n",
    "Similar results were found with different permutations of these two hyperparameters. But we kept the maximum iterations (number of learning epochs) at its highest possible value for the sake of convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with the best set of hyperparameters\n",
    "eta0 = 1, maximum iterations = 10000\n",
    "Different permutations of hyperparameters gave the same mean_test_score\n",
    "We kept the maximum iterations at its highest possible value for the sake of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron(random_state=0, max_iter=10000, eta0 = 1).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115673808279626"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the y value with the aforementioned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8133019799105847"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing confusion matrix to see the accuracy of the actual positives, the false positives and actual negatives and the false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23494  1996]\n",
      " [ 4435  4521]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the classification report to see the precision and recall for the different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88     25490\n",
      "           1       0.69      0.50      0.58      8956\n",
      "\n",
      "    accuracy                           0.81     34446\n",
      "   macro avg       0.77      0.71      0.73     34446\n",
      "weighted avg       0.80      0.81      0.80     34446\n",
      "\n",
      "Classification report\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Classification report\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
